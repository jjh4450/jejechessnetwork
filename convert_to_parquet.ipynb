{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 체스 데이터를 Parquet 파일로 변환\n",
    "\n",
    "이 노트북은 `.pgn.zst` 파일을 읽어서 학습 가능한 parquet 파일로 변환합니다.\n",
    "\n",
    "## 처리 과정\n",
    "1. `.pgn.zst` 파일을 스트리밍으로 읽기\n",
    "2. 각 게임에서 샘플 추출\n",
    "3. 배치 단위로 parquet 파일에 저장\n",
    "4. 메모리 효율적인 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T19:54:51.974596200Z",
     "start_time": "2026-01-24T19:54:51.408592500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from preprocessing import extract_samples_from_pgn_zst\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T19:54:52.003229600Z",
     "start_time": "2026-01-24T19:54:51.976595300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 파일: data/lichess_db_standard_rated_2016-12.pgn.zst\n",
      "출력 디렉토리: data/parquet\n",
      "배치 크기: 100000\n",
      "\n",
      "필터 설정:\n",
      "  최소 레이팅: 1800\n",
      "  최소 시간 제어: 300초 (5분)\n",
      "\n",
      "Mask 생성: 비활성화 (속도 향상)\n"
     ]
    }
   ],
   "source": [
    "# 입력 파일 경로\n",
    "INPUT_ZST_PATH = \"data/lichess_db_standard_rated_2016-12.pgn.zst\"\n",
    "\n",
    "# 출력 디렉토리\n",
    "OUTPUT_DIR = \"data/parquet\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 배치 설정\n",
    "BATCH_SIZE = 100000  # 한 번에 처리할 샘플 수\n",
    "MAX_GAMES = None  # None이면 전체 게임 처리\n",
    "MAX_SAMPLES = None  # None이면 제한 없음\n",
    "\n",
    "# 필터 설정\n",
    "MIN_RATING = 1800  # 최소 레이팅 (양쪽 플레이어 모두 이 값 이상)\n",
    "                   # None이면 필터링 안 함\n",
    "                   # 예: 2000 = 2000 이상, 1800 = 1800 이상\n",
    "\n",
    "MIN_TIME_CONTROL = 300  # 최소 시간 제어 (초 단위, 초기 시간)\n",
    "                        # None이면 필터링 안 함\n",
    "                        # 예: 300 = 5분 이상, 600 = 10분 이상, 1800 = 30분 이상\n",
    "                        # 참고: 300초 = 5분, 600초 = 10분, 1800초 = 30분\n",
    "\n",
    "# Mask 생성 설정\n",
    "GENERATE_MASK = False  # True면 legal_move_mask 생성, False면 생성 안 함\n",
    "                       # 학습 시 필요하면 동적으로 생성 가능\n",
    "\n",
    "# 출력 파일명 패턴\n",
    "OUTPUT_PATTERN = os.path.join(OUTPUT_DIR, \"chess_samples_{:04d}.parquet\")\n",
    "\n",
    "print(f\"입력 파일: {INPUT_ZST_PATH}\")\n",
    "print(f\"출력 디렉토리: {OUTPUT_DIR}\")\n",
    "print(f\"배치 크기: {BATCH_SIZE}\")\n",
    "print(f\"\\n필터 설정:\")\n",
    "print(f\"  최소 레이팅: {MIN_RATING if MIN_RATING else '필터링 안 함'}\")\n",
    "print(f\"  최소 시간 제어: {MIN_TIME_CONTROL}초 ({MIN_TIME_CONTROL//60}분)\" if MIN_TIME_CONTROL else \"  최소 시간 제어: 필터링 안 함\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플을 DataFrame으로 변환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T19:54:52.017248100Z",
     "start_time": "2026-01-24T19:54:52.005229500Z"
    }
   },
   "outputs": [],
   "source": [
    "def samples_to_dataframe(samples):\n",
    "    \"\"\"\n",
    "    샘플 리스트를 pandas DataFrame으로 변환 (NumPy 최적화 버전)\n",
    "    \n",
    "    Args:\n",
    "        samples: [(state, policy, mask, value), ...] 리스트\n",
    "        \n",
    "    Returns:\n",
    "        pandas DataFrame\n",
    "    \"\"\"\n",
    "    n = len(samples)\n",
    "    \n",
    "    # NumPy 배열로 미리 할당 (속도 최적화)\n",
    "    states = np.zeros((n, 18 * 8 * 8), dtype=np.float32)\n",
    "    policies = np.zeros(n, dtype=np.int32)\n",
    "    masks = np.zeros((n, 4096), dtype=np.float32)\n",
    "    values = np.zeros(n, dtype=np.float32)\n",
    "    \n",
    "    # 벡터화된 할당\n",
    "    for i, (state, policy, mask, value) in enumerate(samples):\n",
    "        states[i] = state.flatten()\n",
    "        policies[i] = policy\n",
    "        masks[i] = mask\n",
    "        values[i] = value\n",
    "    \n",
    "    # Parquet 저장을 위해 리스트로 변환 (한 번에 처리)\n",
    "    return pd.DataFrame({\n",
    "        'state': [s.tolist() for s in states],\n",
    "        'policy': policies,\n",
    "        'mask': [m.tolist() for m in masks],\n",
    "        'value': values\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치 단위로 샘플 추출 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T19:54:52.036192700Z",
     "start_time": "2026-01-24T19:54:52.018249400Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_and_save_batches(zst_path, output_pattern, batch_size, max_games=None, max_samples=None, \n",
    "                             min_rating=None, min_time_control=None):\n",
    "    \"\"\"\n",
    "    .pgn.zst 파일을 배치 단위로 처리하여 parquet 파일로 저장\n",
    "    \n",
    "    Args:\n",
    "        zst_path: 입력 .pgn.zst 파일 경로\n",
    "        output_pattern: 출력 파일 패턴 (예: \"data/parquet/samples_{:04d}.parquet\")\n",
    "        batch_size: 배치 크기\n",
    "        max_games: 최대 게임 수 (None이면 제한 없음)\n",
    "        max_samples: 최대 샘플 수 (None이면 제한 없음)\n",
    "        min_rating: 최소 레이팅 (양쪽 플레이어 모두 이 값 이상)\n",
    "        min_time_control: 최소 시간 제어 (초 단위, 초기 시간)\n",
    "    \"\"\"\n",
    "    import zstandard as zstd\n",
    "    import chess.pgn\n",
    "    import io\n",
    "    from preprocessing import (\n",
    "        board_to_tensor,\n",
    "        legal_move_mask,\n",
    "        policy_label_from_move,\n",
    "        game_result_to_value,\n",
    "        should_include_game\n",
    "    )\n",
    "    \n",
    "    batch_samples = []\n",
    "    file_idx = 0\n",
    "    total_samples = 0\n",
    "    total_games = 0\n",
    "    skipped_games = 0\n",
    "    included_games = 0\n",
    "    \n",
    "    with open(zst_path, \"rb\") as f:\n",
    "        dctx = zstd.ZstdDecompressor()\n",
    "        with dctx.stream_reader(f) as binary_reader:\n",
    "            # 바이너리 스트림을 텍스트 스트림으로 변환\n",
    "            text_reader = io.TextIOWrapper(binary_reader, encoding='utf-8', errors='ignore')\n",
    "            pbar = tqdm(desc=\"게임 처리 중\")\n",
    "            \n",
    "            while True:\n",
    "                game = chess.pgn.read_game(text_reader)\n",
    "                if game is None:\n",
    "                    break\n",
    "                \n",
    "                # 필터링 조건 확인\n",
    "                if not should_include_game(game, min_rating, min_time_control):\n",
    "                    skipped_games += 1\n",
    "                    total_games += 1\n",
    "                    pbar.set_postfix({\n",
    "                        '포함': included_games,\n",
    "                        '제외': skipped_games,\n",
    "                        '샘플': total_samples\n",
    "                    })\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                included_games += 1\n",
    "                board = game.board()\n",
    "                result = game.headers.get(\"Result\", \"*\")\n",
    "                \n",
    "                # 게임의 각 수마다 샘플 생성\n",
    "                for move in game.mainline_moves():\n",
    "                    state = board_to_tensor(board)\n",
    "                    policy = policy_label_from_move(move)\n",
    "                    mask = legal_move_mask(board)\n",
    "                    value = game_result_to_value(result, board.turn)\n",
    "                    \n",
    "                    batch_samples.append((state, policy, mask, value))\n",
    "                    board.push(move)\n",
    "                    \n",
    "                    # 배치가 가득 차면 저장\n",
    "                    if len(batch_samples) >= batch_size:\n",
    "                        df = samples_to_dataframe(batch_samples)\n",
    "                        output_path = output_pattern.format(file_idx)\n",
    "                        # Parquet 저장 최적화 (row_group_size로 I/O 성능 향상)\n",
    "                        df.to_parquet(\n",
    "                            output_path, \n",
    "                            index=False, \n",
    "                            engine='pyarrow',\n",
    "                            row_group_size=min(50000, len(df))  # 큰 row group으로 I/O 최적화\n",
    "                        )\n",
    "                        \n",
    "                        total_samples += len(batch_samples)\n",
    "                        file_idx += 1\n",
    "                        batch_samples = []\n",
    "                        \n",
    "                        pbar.set_postfix({\n",
    "                            '파일': file_idx,\n",
    "                            '샘플': total_samples,\n",
    "                            '게임': total_games\n",
    "                        })\n",
    "                    \n",
    "                    # 샘플 수 제한 체크\n",
    "                    if max_samples and total_samples + len(batch_samples) >= max_samples:\n",
    "                        break\n",
    "                \n",
    "                total_games += 1\n",
    "                pbar.set_postfix({\n",
    "                    '포함': included_games,\n",
    "                    '제외': skipped_games,\n",
    "                    '샘플': total_samples\n",
    "                })\n",
    "                pbar.update(1)\n",
    "                \n",
    "                # 게임 수 제한 체크\n",
    "                if max_games and total_games >= max_games:\n",
    "                    break\n",
    "                \n",
    "                # 샘플 수 제한 체크\n",
    "                if max_samples and total_samples + len(batch_samples) >= max_samples:\n",
    "                    break\n",
    "            \n",
    "            # 남은 샘플 저장\n",
    "            if batch_samples:\n",
    "                df = samples_to_dataframe(batch_samples)\n",
    "                output_path = output_pattern.format(file_idx)\n",
    "                df.to_parquet(\n",
    "                    output_path, \n",
    "                    index=False, \n",
    "                    engine='pyarrow',\n",
    "                    row_group_size=min(50000, len(df))\n",
    "                )\n",
    "                total_samples += len(batch_samples)\n",
    "                file_idx += 1\n",
    "            \n",
    "            pbar.close()\n",
    "    \n",
    "    print(f\"\\n변환 완료!\")\n",
    "    print(f\"  총 게임 수: {total_games:,}\")\n",
    "    print(f\"  포함된 게임 수: {included_games:,}\")\n",
    "    print(f\"  제외된 게임 수: {skipped_games:,}\")\n",
    "    print(f\"  총 샘플 수: {total_samples:,}\")\n",
    "    print(f\"  생성된 파일 수: {file_idx + 1}\")\n",
    "    if total_games > 0:\n",
    "        print(f\"  포함 비율: {included_games/total_games*100:.2f}%\")\n",
    "    return total_samples, file_idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변환 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T19:58:17.117864500Z",
     "start_time": "2026-01-24T19:54:52.038191600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "게임 처리 중: 4144it [00:14, 276.17it/s, 포함=263, 제외=3882, 샘플=0]"
     ]
    }
   ],
   "source": [
    "# 파일 존재 확인\n",
    "if not os.path.exists(INPUT_ZST_PATH):\n",
    "    print(f\"⚠️  입력 파일을 찾을 수 없습니다: {INPUT_ZST_PATH}\")\n",
    "    print(\"파일 경로를 확인하세요.\")\n",
    "else:\n",
    "    # 변환 실행\n",
    "    total_samples, num_files = process_and_save_batches(\n",
    "        zst_path=INPUT_ZST_PATH,\n",
    "        output_pattern=OUTPUT_PATTERN,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        max_games=MAX_GAMES,\n",
    "        max_samples=MAX_SAMPLES,\n",
    "        min_rating=MIN_RATING,\n",
    "        min_time_control=MIN_TIME_CONTROL\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 생성된 Parquet 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 파일 목록 확인\n",
    "parquet_files = sorted(Path(OUTPUT_DIR).glob(\"chess_samples_*.parquet\"))\n",
    "print(f\"생성된 파일 수: {len(parquet_files)}\")\n",
    "\n",
    "if parquet_files:\n",
    "    # 첫 번째 파일 읽어서 확인\n",
    "    first_file = parquet_files[0]\n",
    "    print(f\"\\n첫 번째 파일 확인: {first_file.name}\")\n",
    "    \n",
    "    df = pd.read_parquet(first_file)\n",
    "    print(f\"  행 수: {len(df)}\")\n",
    "    print(f\"  컬럼: {df.columns.tolist()}\")\n",
    "    print(f\"\\n  첫 번째 샘플:\")\n",
    "    print(f\"    Policy: {df.iloc[0]['policy']}\")\n",
    "    print(f\"    Value: {df.iloc[0]['value']}\")\n",
    "    print(f\"    State shape (평탄화): {len(df.iloc[0]['state'])} (예상: 1152)\")\n",
    "    print(f\"    Mask shape (평탄화): {len(df.iloc[0]['mask'])} (예상: 4096)\")\n",
    "    \n",
    "    # State 복원 테스트\n",
    "    state_flat = np.array(df.iloc[0]['state'], dtype=np.float32)\n",
    "    state_restored = state_flat.reshape(18, 8, 8)\n",
    "    print(f\"    State 복원 shape: {state_restored.shape}\")\n",
    "    \n",
    "    # Mask 복원 테스트\n",
    "    mask_flat = np.array(df.iloc[0]['mask'], dtype=np.float32)\n",
    "    mask_restored = mask_flat.reshape(4096)\n",
    "    print(f\"    Mask 복원 shape: {mask_restored.shape}\")\n",
    "    print(f\"    합법 수 개수: {int(mask_restored.sum())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet 파일에서 데이터 로드하는 함수 (학습용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_from_parquet(df_row):\n",
    "    \"\"\"\n",
    "    Parquet 파일의 한 행을 원래 형태로 복원\n",
    "    \n",
    "    Args:\n",
    "        df_row: pandas DataFrame의 한 행\n",
    "        \n",
    "    Returns:\n",
    "        (state, policy, mask, value) 튜플\n",
    "    \"\"\"\n",
    "    state = np.array(df_row['state'], dtype=np.float32).reshape(18, 8, 8)\n",
    "    policy = int(df_row['policy'])\n",
    "    mask = np.array(df_row['mask'], dtype=np.float32)\n",
    "    value = float(df_row['value'])\n",
    "    \n",
    "    return state, policy, mask, value\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "if parquet_files:\n",
    "    print(\"샘플 로드 테스트:\")\n",
    "    df = pd.read_parquet(parquet_files[0])\n",
    "    state, policy, mask, value = load_sample_from_parquet(df.iloc[0])\n",
    "    \n",
    "    print(f\"  State shape: {state.shape}\")\n",
    "    print(f\"  Policy: {policy}\")\n",
    "    print(f\"  Mask shape: {mask.shape}, 합법 수: {int(mask.sum())}\")\n",
    "    print(f\"  Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataset 클래스 (Parquet 파일용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class ParquetChessDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Parquet 파일에서 체스 데이터를 로드하는 Dataset\n",
    "    \n",
    "    여러 parquet 파일을 하나의 Dataset으로 처리합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, parquet_dir, file_pattern=\"chess_samples_*.parquet\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            parquet_dir: parquet 파일이 있는 디렉토리\n",
    "            file_pattern: 파일 패턴\n",
    "        \"\"\"\n",
    "        self.parquet_dir = Path(parquet_dir)\n",
    "        self.parquet_files = sorted(self.parquet_dir.glob(file_pattern))\n",
    "        \n",
    "        if not self.parquet_files:\n",
    "            raise ValueError(f\"Parquet 파일을 찾을 수 없습니다: {parquet_dir}/{file_pattern}\")\n",
    "        \n",
    "        # 각 파일의 행 수를 미리 계산\n",
    "        self.file_lengths = []\n",
    "        self.cumulative_lengths = [0]\n",
    "        \n",
    "        print(f\"Parquet 파일 로드 중... ({len(self.parquet_files)}개 파일)\")\n",
    "        for file_path in tqdm(self.parquet_files, desc=\"파일 인덱싱\"):\n",
    "            df = pd.read_parquet(file_path)\n",
    "            length = len(df)\n",
    "            self.file_lengths.append(length)\n",
    "            self.cumulative_lengths.append(self.cumulative_lengths[-1] + length)\n",
    "        \n",
    "        self.total_length = self.cumulative_lengths[-1]\n",
    "        print(f\"총 샘플 수: {self.total_length:,}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 어떤 파일에 속하는지 찾기\n",
    "        file_idx = 0\n",
    "        for i, cum_len in enumerate(self.cumulative_lengths[1:], 1):\n",
    "            if idx < cum_len:\n",
    "                file_idx = i - 1\n",
    "                break\n",
    "        \n",
    "        # 파일 내 상대 인덱스\n",
    "        local_idx = idx - self.cumulative_lengths[file_idx]\n",
    "        \n",
    "        # 파일 로드 (캐싱 가능하지만 메모리 고려)\n",
    "        df = pd.read_parquet(self.parquet_files[file_idx])\n",
    "        row = df.iloc[local_idx]\n",
    "        \n",
    "        # 데이터 복원\n",
    "        state, policy, mask, value = load_sample_from_parquet(row)\n",
    "        \n",
    "        return (\n",
    "            torch.from_numpy(state).float(),\n",
    "            torch.tensor(policy, dtype=torch.long),\n",
    "            torch.from_numpy(mask).float(),\n",
    "            torch.tensor(value, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "\n",
    "# Dataset 테스트\n",
    "if parquet_files:\n",
    "    print(\"\\nDataset 테스트:\")\n",
    "    dataset = ParquetChessDataset(OUTPUT_DIR)\n",
    "    print(f\"  Dataset 크기: {len(dataset):,}\")\n",
    "    \n",
    "    # 첫 번째 샘플 확인\n",
    "    state, policy, mask, value = dataset[0]\n",
    "    print(f\"  첫 번째 샘플:\")\n",
    "    print(f\"    State: {state.shape}, dtype: {state.dtype}\")\n",
    "    print(f\"    Policy: {policy}, dtype: {policy.dtype}\")\n",
    "    print(f\"    Mask: {mask.shape}, dtype: {mask.dtype}\")\n",
    "    print(f\"    Value: {value}, dtype: {value.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader 사용 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if parquet_files:\n",
    "    # Dataset 생성\n",
    "    dataset = ParquetChessDataset(OUTPUT_DIR)\n",
    "    \n",
    "    # DataLoader 생성\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=0  # Windows에서는 0 권장\n",
    "    )\n",
    "    \n",
    "    # 배치 확인\n",
    "    print(\"DataLoader 테스트:\")\n",
    "    for batch_idx, (states, policies, masks, values) in enumerate(dataloader):\n",
    "        print(f\"  배치 {batch_idx + 1}:\")\n",
    "        print(f\"    States: {states.shape}\")\n",
    "        print(f\"    Policies: {policies.shape}\")\n",
    "        print(f\"    Masks: {masks.shape}\")\n",
    "        print(f\"    Values: {values.shape}\")\n",
    "        \n",
    "        if batch_idx >= 2:  # 처음 3개 배치만 출력\n",
    "            break\n",
    "    \n",
    "    print(\"\\n✅ Parquet 파일이 학습 가능한 형태로 준비되었습니다!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
