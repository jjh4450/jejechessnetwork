{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN ëª¨ë¸ í‰ê°€\n",
    "\n",
    "í•™ìŠµëœ ChessCNN ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì‹¤í–‰ ìˆœì„œ\n",
    "ëª¨ë“  ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "## í‰ê°€ ë©”íŠ¸ë¦­\n",
    "- **Top-k Accuracy**: ì •ë‹µì´ ìƒìœ„ kê°œ ì˜ˆì¸¡ ì•ˆì— í¬í•¨ë˜ëŠ” ë¹„ìœ¨\n",
    "- **Masked Accuracy**: í•©ë²• ìˆ˜ë§Œ ê³ ë ¤í•œ ì •í™•ë„\n",
    "- **MRR (Mean Reciprocal Rank)**: ì •ë‹µ ìˆœìœ„ì˜ ì—­ìˆ˜ í‰ê· \n",
    "- **Entropy**: ì •ì±… ë¶„í¬ì˜ ë¶ˆí™•ì‹¤ì„±\n",
    "- **Legal Prob Mass**: í•©ë²• ìˆ˜ì— í• ë‹¹ëœ í™•ë¥  ì§ˆëŸ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T18:20:19.988068800Z",
     "start_time": "2026-02-03T18:20:18.909478600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ì¥ì¹˜: cuda\n",
      "  GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "  GPU ë©”ëª¨ë¦¬: 15.93 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "from parquet_dataset import (\n",
    "    ParquetChessDataset,\n",
    "    get_parquet_file_info, \n",
    "    split_files_by_ratio\n",
    ")\n",
    "from chess_model import ChessCNN, load_model\n",
    "from train_utils import validate\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ì‚¬ìš© ì¥ì¹˜: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T18:20:21.508692400Z",
     "start_time": "2026-02-03T18:20:20.925438200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¡œë“œëœ ëª¨ë¸ ì •ë³´:\n",
      "  íŒŒì¼: models/best_chess_cnn.pth\n",
      "  Epoch: 5\n",
      "  Validation Loss: 2.6870\n",
      "  Validation Accuracy: 44.69%\n",
      "  Train Loss: 2.6012\n",
      "  Learning Rate: 0.008000\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ê²½ë¡œ ì„¤ì •\n",
    "MODEL_DIR = Path(\"models\")\n",
    "BEST_MODEL_PATH = MODEL_DIR / \"best_chess_cnn.pth\"\n",
    "LAST_MODEL_PATH = MODEL_DIR / \"last_chess_cnn.pth\"\n",
    "\n",
    "# í‰ê°€í•  ëª¨ë¸ ì„ íƒ (best ë˜ëŠ” last)\n",
    "MODEL_PATH = BEST_MODEL_PATH  # ë³€ê²½ ê°€ëŠ¥: LAST_MODEL_PATH\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model, checkpoint = load_model(MODEL_PATH, device=device)\n",
    "\n",
    "print(f\"ë¡œë“œëœ ëª¨ë¸ ì •ë³´:\")\n",
    "print(f\"  íŒŒì¼: {MODEL_PATH}\")\n",
    "print(f\"  Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "print(f\"  Validation Loss: {checkpoint.get('val_loss', 'N/A'):.4f}\")\n",
    "print(f\"  Validation Accuracy: {checkpoint.get('val_accuracy', 'N/A')*100:.2f}%\")\n",
    "if 'train_loss' in checkpoint:\n",
    "    print(f\"  Train Loss: {checkpoint['train_loss']:.4f}\")\n",
    "if 'learning_rate' in checkpoint:\n",
    "    print(f\"  Learning Rate: {checkpoint['learning_rate']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê²€ì¦ ë°ì´í„°ì…‹ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T18:20:23.958183500Z",
     "start_time": "2026-02-03T18:20:22.980994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ì„¤ì •\n",
    "PARQUET_DIR = \"data/parquet\"\n",
    "TRAIN_RATIO = 0.9\n",
    "BATCH_SIZE = 4096\n",
    "CHUNK_SIZE = 32768\n",
    "\n",
    "# íŒŒì¼ ì •ë³´ ìˆ˜ì§‘ ë° ë¶„í•  (val_filesë§Œ ì‚¬ìš©)\n",
    "parquet_files, file_lengths = get_parquet_file_info(PARQUET_DIR, \"chess_samples_*.parquet\")\n",
    "_, val_files, _, val_lengths, _, val_samples = split_files_by_ratio(\n",
    "    parquet_files, \n",
    "    file_lengths, \n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±\n",
    "print(\"\\nê²€ì¦ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\")\n",
    "val_dataset = ParquetChessDataset(\n",
    "    parquet_files=val_files,\n",
    "    file_lengths=val_lengths,\n",
    "    shuffle_files=False,\n",
    "    seed=42,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    chunk_size=CHUNK_SIZE\n",
    ")\n",
    "\n",
    "print(f\"ê²€ì¦ ë°ì´í„°: {val_dataset.estimated_length:,} ìƒ˜í”Œ\")\n",
    "\n",
    "VAL_STEPS = val_dataset.estimated_length // BATCH_SIZE\n",
    "print(f\"ê²€ì¦ ì´í„°ë ˆì´ì…˜: {VAL_STEPS:,} steps\")\n",
    "\n",
    "# DataLoader (ì›Œì»¤ ì—†ì´ - ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=None,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "print(\"\\në°ì´í„° ë¡œë”© ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T18:23:28.874619200Z",
     "start_time": "2026-02-03T18:20:25.056676100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss í•¨ìˆ˜ ë° ì„¤ì •\n",
    "policy_loss_fn = nn.CrossEntropyLoss()\n",
    "value_loss_fn = nn.MSELoss()\n",
    "POLICY_WEIGHT = 1.0\n",
    "VALUE_WEIGHT = 1.0\n",
    "USE_AMP = torch.cuda.is_available()\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "print(\"=\"*60)\n",
    "print(\"ëª¨ë¸ í‰ê°€ ì‹œì‘\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metrics = validate(\n",
    "    model, val_loader, policy_loss_fn, value_loss_fn,\n",
    "    POLICY_WEIGHT, VALUE_WEIGHT, device,\n",
    "    use_amp=USE_AMP, total_steps=VAL_STEPS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T18:27:32.364761600Z",
     "start_time": "2026-02-03T18:27:32.312181800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "í‰ê°€ ê²°ê³¼\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Loss:\n",
      "  Policy Loss: 1.7733\n",
      "  Value Loss: 0.9136\n",
      "  Total Loss: 2.6870\n",
      "\n",
      "ğŸ¯ ì •í™•ë„ (ë§ˆìŠ¤í¬ ë¯¸ì ìš©):\n",
      "  Top-1: 44.69%\n",
      "  Top-3: 72.93%\n",
      "  Top-5: 83.73%\n",
      "  Top-10: 94.04%\n",
      "\n",
      "âœ… ì •í™•ë„ (ë§ˆìŠ¤í¬ ì ìš©):\n",
      "  Masked Top-1: 44.69%\n",
      "\n",
      "ğŸ“ˆ Rank ë¶„ì„:\n",
      "  MRR (Mean Reciprocal Rank): 0.6146\n",
      "  Average Rank: 3.32\n",
      "\n",
      "ğŸ“‰ ë¶„í¬ ë¶„ì„:\n",
      "  Entropy (í•©ë²• ìˆ˜ ê¸°ì¤€): 1.6324\n",
      "  Legal Prob Mass: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"í‰ê°€ ê²°ê³¼\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸ“Š Loss:\")\n",
    "print(f\"  Policy Loss: {metrics['policy_loss']:.4f}\")\n",
    "print(f\"  Value Loss: {metrics['value_loss']:.4f}\")\n",
    "print(f\"  Total Loss: {metrics['total_loss']:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì •í™•ë„ (ë§ˆìŠ¤í¬ ë¯¸ì ìš©):\")\n",
    "print(f\"  Top-1: {metrics['accuracy']*100:.2f}%\")\n",
    "print(f\"  Top-3: {metrics['top3_acc']*100:.2f}%\")\n",
    "print(f\"  Top-5: {metrics['top5_acc']*100:.2f}%\")\n",
    "print(f\"  Top-10: {metrics['top10_acc']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nâœ… ì •í™•ë„ (ë§ˆìŠ¤í¬ ì ìš©):\")\n",
    "print(f\"  Masked Top-1: {metrics['masked_acc']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Rank ë¶„ì„:\")\n",
    "print(f\"  MRR (Mean Reciprocal Rank): {metrics['mrr']:.4f}\")\n",
    "print(f\"  Average Rank: {metrics['avg_rank']:.2f}\")\n",
    "\n",
    "print(f\"\\nğŸ“‰ ë¶„í¬ ë¶„ì„:\")\n",
    "print(f\"  Entropy (í•©ë²• ìˆ˜ ê¸°ì¤€): {metrics['entropy']:.4f}\")\n",
    "print(f\"  Legal Prob Mass: {metrics['legal_prob_mass']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìƒ˜í”Œ ì˜ˆì¸¡ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª‡ ê°œ ìƒ˜í”Œë¡œ ì˜ˆì¸¡ í™•ì¸\n",
    "model.eval()\n",
    "non_blocking = torch.cuda.is_available()\n",
    "\n",
    "# ìƒˆ ë°ì´í„°ì…‹ ì´í„°ë ˆì´í„° ìƒì„±\n",
    "sample_dataset = ParquetChessDataset(\n",
    "    parquet_files=val_files[:1],  # ì²« íŒŒì¼ë§Œ\n",
    "    file_lengths=val_lengths[:1],\n",
    "    shuffle_files=False,\n",
    "    seed=42,\n",
    "    batch_size=16,\n",
    "    chunk_size=1024\n",
    ")\n",
    "sample_loader = DataLoader(sample_dataset, batch_size=None, num_workers=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for states, policies, masks, values in sample_loader:\n",
    "        states = states.to(device, non_blocking=non_blocking)\n",
    "        masks = masks.to(device, non_blocking=non_blocking)\n",
    "        \n",
    "        policy_logits, value_pred = model(states, masks)\n",
    "        policy_probs = torch.softmax(policy_logits, dim=1)\n",
    "        pred_policies = policy_logits.argmax(dim=1)\n",
    "        \n",
    "        print(\"ìƒ˜í”Œ ì˜ˆì¸¡:\")\n",
    "        for i in range(min(5, len(states))):\n",
    "            print(f\"\\nìƒ˜í”Œ {i+1}:\")\n",
    "            print(f\"  ì‹¤ì œ Policy: {policies[i].item()}\")\n",
    "            print(f\"  ì˜ˆì¸¡ Policy: {pred_policies[i].item()}\")\n",
    "            print(f\"  ì •í™•ë„: {'âœ…' if pred_policies[i] == policies[i] else 'âŒ'}\")\n",
    "            print(f\"  ì‹¤ì œ Value: {values[i].item():.4f}\")\n",
    "            print(f\"  ì˜ˆì¸¡ Value: {value_pred[i].item():.4f}\")\n",
    "            print(f\"  ì˜ˆì¸¡ í™•ë¥  (top-1): {policy_probs[i].max().item():.4f}\")\n",
    "        \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
