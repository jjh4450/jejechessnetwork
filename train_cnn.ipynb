{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN ÏßÄÎèÑÌïôÏäµ\n",
    "\n",
    "Ï≤¥Ïä§ Îç∞Ïù¥ÌÑ∞Î°ú CNN Î™®Îç∏ÏùÑ ÏßÄÎèÑÌïôÏäµÌï©ÎãàÎã§.\n",
    "\n",
    "Ïù¥ Î™®Îç∏ÏùÄ Ïù¥ÌõÑ Í∞ïÌôîÌïôÏäµÏùò Ï†ïÏ±Ö Ïã†Í≤ΩÎßùÏúºÎ°ú ÏÇ¨Ïö©Îê©ÎãàÎã§.\n",
    "\n",
    "## Î™®Îç∏ Íµ¨Ï°∞\n",
    "- **ÏûÖÎ†•**: (18, 8, 8) Ï≤¥Ïä§ Î≥¥Îìú ÏÉÅÌÉú\n",
    "- **Policy Head**: 4096Í∞ú Ïï°ÏÖòÏóê ÎåÄÌïú ÌôïÎ•† Î∂ÑÌè¨\n",
    "- **Value Head**: Ìè¨ÏßÄÏÖò ÌèâÍ∞ÄÍ∞í (-1 ~ 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-31T08:53:53.387278600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CUDA ÏÇ¨Ïö© Í∞ÄÎä•!\n",
      "   GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "   CUDA Î≤ÑÏ†Ñ: 13.1\n",
      "   PyTorch Î≤ÑÏ†Ñ: 2.10.0a0+b4e4ee81d3.nv25.12\n",
      "   GPU Î©îÎ™®Î¶¨: 15.93 GB\n",
      "\n",
      "ÏÇ¨Ïö© Ïû•Ïπò: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from parquet_dataset import (\n",
    "    ParquetChessDataset,\n",
    "    get_parquet_file_info, \n",
    "    split_files_by_ratio\n",
    ")\n",
    "from train_utils import create_tensorboard_writer, train_epoch, validate\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"‚úÖ CUDA ÏÇ¨Ïö© Í∞ÄÎä•!\")\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA Î≤ÑÏ†Ñ: {torch.version.cuda}\")\n",
    "    print(f\"   PyTorch Î≤ÑÏ†Ñ: {torch.__version__}\")\n",
    "    print(f\"   GPU Î©îÎ™®Î¶¨: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"‚ö†Ô∏è  CUDA ÏÇ¨Ïö© Î∂àÍ∞Ä - CPU ÏÇ¨Ïö©\")\n",
    "    print(f\"   PyTorch Î≤ÑÏ†Ñ: {torch.__version__}\")\n",
    "\n",
    "print(f\"\\nÏÇ¨Ïö© Ïû•Ïπò: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Î™®Îç∏ Ï†ïÏùò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T20:06:44.614362Z",
     "start_time": "2026-01-26T20:06:43.671729500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ Ïàò: 9,314,433\n",
      "ÌïôÏäµ Í∞ÄÎä• ÌååÎùºÎØ∏ÌÑ∞ Ïàò: 9,314,433\n",
      "\n",
      "ÏûÖÎ†• shape: torch.Size([2, 18, 8, 8])\n",
      "Policy logits shape: torch.Size([2, 4096])\n",
      "Value shape: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "class ChessCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Ï≤¥Ïä§ CNN Î™®Îç∏\n",
    "    \n",
    "    Policy HeadÏôÄ Value HeadÎ•º Í∞ÄÏßÑ Íµ¨Ï°∞Î°ú,\n",
    "    ÏßÄÎèÑÌïôÏäµ ÌõÑ Í∞ïÌôîÌïôÏäµÏùò Ï†ïÏ±Ö Ïã†Í≤ΩÎßùÏúºÎ°ú ÏÇ¨Ïö©Îê©ÎãàÎã§.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_channels=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ÏûÖÎ†•: (batch, 18, 8, 8)\n",
    "        # Í≥µÌÜµ CNN Î∞±Î≥∏\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Ï≤´ Î≤àÏß∏ Î∏îÎ°ù\n",
    "            nn.Conv2d(18, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Îëê Î≤àÏß∏ Î∏îÎ°ù\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # ÏÑ∏ Î≤àÏß∏ Î∏îÎ°ù\n",
    "            nn.Conv2d(128, num_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(num_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Policy Head (4096Í∞ú Ïï°ÏÖò)\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 32, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 8 * 8, 4096),\n",
    "        )\n",
    "        \n",
    "        # Value Head (1Í∞ú Ï∂úÎ†•)\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 32, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, 18, 8, 8) ÏûÖÎ†• ÌÖêÏÑú\n",
    "            mask: (batch, 4096) Ìï©Î≤ï Ïàò ÎßàÏä§ÌÅ¨ (ÏÑ†ÌÉùÏÇ¨Ìï≠)\n",
    "        \n",
    "        Returns:\n",
    "            policy_logits: (batch, 4096) Ï†ïÏ±Ö Î°úÏßì\n",
    "            value: (batch, 1) Í∞ÄÏπò ÏòàÏ∏°\n",
    "        \"\"\"\n",
    "        # Í≥µÌÜµ Î∞±Î≥∏\n",
    "        features = self.conv_layers(x)\n",
    "        \n",
    "        # Policy Head\n",
    "        policy_logits = self.policy_head(features)\n",
    "        \n",
    "        # Mask Ï†ÅÏö© (Î∂àÎ≤ï Ïàò Ï†úÍ±∞)\n",
    "        if mask is not None:\n",
    "            illegal_mask = mask < 0.5\n",
    "            policy_logits = policy_logits.masked_fill(illegal_mask, float('-inf'))\n",
    "        \n",
    "        # Value Head\n",
    "        value = self.value_head(features)\n",
    "        \n",
    "        return policy_logits, value\n",
    "\n",
    "\n",
    "model = ChessCNN(num_channels=256).to(device)\n",
    "\n",
    "# model = torch.compile(model, mode='default')\n",
    "\n",
    "print(f\"Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ Ïàò: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"ÌïôÏäµ Í∞ÄÎä• ÌååÎùºÎØ∏ÌÑ∞ Ïàò: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "sample_input = torch.randn(2, 18, 8, 8).to(device)\n",
    "sample_mask = torch.ones(2, 4096).to(device)\n",
    "policy_logits, value = model(sample_input, sample_mask)\n",
    "print(f\"\\nÏûÖÎ†• shape: {sample_input.shape}\")\n",
    "print(f\"Policy logits shape: {policy_logits.shape}\")\n",
    "print(f\"Value shape: {value.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Îç∞Ïù¥ÌÑ∞ÏÖã ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T20:07:54.446746200Z",
     "start_time": "2026-01-26T20:06:47.746709900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet ÌååÏùº Ï†ïÎ≥¥ ÏàòÏßë Ï§ë... (449Í∞ú ÌååÏùº)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÌååÏùº Ïä§Ï∫î: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 449/449 [00:01<00:00, 420.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï¥ù ÌååÏùº Ïàò: 449, Ï¥ù ÏÉòÌîå Ïàò: 22,450,000\n",
      "\n",
      "ÌååÏùº Îã®ÏúÑ Î∂ÑÌï† ÏôÑÎ£å:\n",
      "  Train: 405Í∞ú ÌååÏùº, 20,250,000Í∞ú ÏÉòÌîå (90.2%)\n",
      "  Val: 44Í∞ú ÌååÏùº, 2,200,000Í∞ú ÏÉòÌîå (9.8%)\n",
      "\n",
      "ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ± Ï§ë...\n",
      "ÌååÏùº Í∏∏Ïù¥ Ï†ïÎ≥¥ ÏÇ¨Ïö© (Ïä§Ï∫î ÏÉùÎûµ, 405Í∞ú ÌååÏùº)\n",
      "Ï¥ù ÏÉòÌîå Ïàò: 20,250,000\n",
      "Î™®Îìú: ÌååÏùº ÏàúÏÑú ÏÖîÌîå, Î∞∞Ïπò ÌÅ¨Í∏∞: 4096, Ï≤≠ÌÅ¨ ÌÅ¨Í∏∞: 32768\n",
      "ÌååÏùº Í∏∏Ïù¥ Ï†ïÎ≥¥ ÏÇ¨Ïö© (Ïä§Ï∫î ÏÉùÎûµ, 44Í∞ú ÌååÏùº)\n",
      "Ï¥ù ÏÉòÌîå Ïàò: 2,200,000\n",
      "Î™®Îìú: ÏàúÏ∞® ÏùΩÍ∏∞, Î∞∞Ïπò ÌÅ¨Í∏∞: 4096, Ï≤≠ÌÅ¨ ÌÅ¨Í∏∞: 32768\n",
      "\n",
      "Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ± Ï§ë...\n",
      "\n",
      "ÏµúÏ¢Ö Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¨Í∏∞:\n",
      "  ÌïôÏäµ Îç∞Ïù¥ÌÑ∞: 20,250,000 (Ïä§Ìä∏Î¶¨Î∞ç)\n",
      "  Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞: 2,200,000 (Ïä§Ìä∏Î¶¨Î∞ç)\n",
      "CUDA ÏÇ¨Ïö© Ï§ë\n",
      "  Î∞∞Ïπò ÌÅ¨Í∏∞: 4096 (Í∏∞Ï°¥ 100ÏóêÏÑú 41.0x Ï¶ùÍ∞Ä)\n",
      "  ÏõåÏª§ Ïàò: 5, ÌîÑÎ¶¨Ìå®Ïπò: 8\n",
      "\n",
      "ÏóêÌè≠Îãπ Ïù¥ÌÑ∞Î†àÏù¥ÏÖò:\n",
      "  ÌïôÏäµ: 4,943 steps\n",
      "  Í≤ÄÏ¶ù: 537 steps\n",
      "\n",
      "Ï≤´ Î∞∞Ïπò Î°úÎî© Ï§ë...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Î∞∞Ïπò shape ÌôïÏù∏:\n",
      "  States: torch.Size([4096, 18, 8, 8])\n",
      "  Policies: torch.Size([4096])\n",
      "  Masks: torch.Size([4096, 4096])\n",
      "  Values: torch.Size([4096])\n",
      "\n",
      "Îç∞Ïù¥ÌÑ∞ Î°úÎî© Ï§ÄÎπÑ ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ ÎîîÎ†âÌÜ†Î¶¨ ÏÑ§Ï†ï\n",
    "PARQUET_DIR = \"data/parquet\"\n",
    "TRAIN_RATIO = 0.9\n",
    "\n",
    "# ÌååÏùº Ï†ïÎ≥¥ ÏàòÏßë Î∞è Î∂ÑÌï†\n",
    "parquet_files, file_lengths = get_parquet_file_info(PARQUET_DIR, \"chess_samples_*.parquet\")\n",
    "train_files, val_files, train_lengths, val_lengths, train_samples, val_samples = split_files_by_ratio(\n",
    "    parquet_files, \n",
    "    file_lengths, \n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# ÏÑ±Îä• ÏµúÏ†ÅÌôî ÏÑ§Ï†ï\n",
    "# =============================================================================\n",
    "BASE_BATCH_SIZE = 100   # Í∏∞Ï§Ä Î∞∞Ïπò ÌÅ¨Í∏∞ (ÌïôÏäµÎ•† Ïä§ÏºÄÏùºÎßÅÏö©)\n",
    "BATCH_SIZE = 4096       # RTX 5060 Ti 16GB: 4096 Í∂åÏû• (OOM Î∞úÏÉù Ïãú 2048Î°ú Ï§ÑÏù¥Í∏∞)\n",
    "CHUNK_SIZE = 32768      # Parquet ÌååÏùº ÏùΩÍ∏∞ Ï≤≠ÌÅ¨ ÌÅ¨Í∏∞\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ±\n",
    "print(\"\\nÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ± Ï§ë...\")\n",
    "train_dataset = ParquetChessDataset(\n",
    "    parquet_files=train_files,\n",
    "    file_lengths=train_lengths,\n",
    "    shuffle_files=True,\n",
    "    seed=42,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    chunk_size=CHUNK_SIZE\n",
    ")\n",
    "val_dataset = ParquetChessDataset(\n",
    "    parquet_files=val_files,\n",
    "    file_lengths=val_lengths,\n",
    "    shuffle_files=False,\n",
    "    seed=42,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    chunk_size=CHUNK_SIZE\n",
    ")\n",
    "\n",
    "print(\"\\nÍ≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ± Ï§ë...\")\n",
    "\n",
    "print(f\"\\nÏµúÏ¢Ö Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¨Í∏∞:\")\n",
    "print(f\"  ÌïôÏäµ Îç∞Ïù¥ÌÑ∞: {train_dataset.estimated_length:,} (Ïä§Ìä∏Î¶¨Î∞ç)\")\n",
    "print(f\"  Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞: {val_dataset.estimated_length:,} (Ïä§Ìä∏Î¶¨Î∞ç)\")\n",
    "\n",
    "# Î©ÄÌã∞ ÏõåÏª§ ÏÑ§Ï†ï (GPU ÎåÄÍ∏∞ ÏãúÍ∞Ñ ÏµúÏÜåÌôî)\n",
    "# - Ìò∏Ïä§Ìä∏ RAM 47GB Ïó¨Ïú† ÏûàÏúºÎØÄÎ°ú ÏõåÏª§ Ïàò Ï¶ùÍ∞Ä\n",
    "# - OOM Î∞úÏÉù Ïãú NUM_WORKERS=2Î°ú Ï§ÑÏù¥Í∏∞\n",
    "NUM_WORKERS = 5\n",
    "PREFETCH_FACTOR = 8  # ÏõåÏª§Îãπ ÎØ∏Î¶¨ Î°úÎìúÌï† Î∞∞Ïπò Ïàò\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA ÏÇ¨Ïö© Ï§ë\")\n",
    "    print(f\"  Î∞∞Ïπò ÌÅ¨Í∏∞: {BATCH_SIZE} (Í∏∞Ï°¥ {BASE_BATCH_SIZE}ÏóêÏÑú {BATCH_SIZE/BASE_BATCH_SIZE:.1f}x Ï¶ùÍ∞Ä)\")\n",
    "    print(f\"  ÏõåÏª§ Ïàò: {NUM_WORKERS}, ÌîÑÎ¶¨Ìå®Ïπò: {PREFETCH_FACTOR}\")\n",
    "\n",
    "# ÏóêÌè≠Îãπ ÏòàÏÉÅ Ïù¥ÌÑ∞Î†àÏù¥ÏÖò Ïàò (tqdm ÏßÑÌñâÎ•† ÌëúÏãúÏö©)\n",
    "TRAIN_STEPS_PER_EPOCH = train_dataset.estimated_length // BATCH_SIZE\n",
    "VAL_STEPS_PER_EPOCH = val_dataset.estimated_length // BATCH_SIZE\n",
    "print(f\"\\nÏóêÌè≠Îãπ Ïù¥ÌÑ∞Î†àÏù¥ÏÖò:\")\n",
    "print(f\"  ÌïôÏäµ: {TRAIN_STEPS_PER_EPOCH:,} steps\")\n",
    "print(f\"  Í≤ÄÏ¶ù: {VAL_STEPS_PER_EPOCH:,} steps\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=None,  # DatasetÏù¥ Ïù¥ÎØ∏ Î∞∞ÏπòÎ•º Î∞òÌôòÌïòÎØÄÎ°ú None\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=False,  # Í≥µÏú† GPU Î©îÎ™®Î¶¨ ÏÇ¨Ïö© Ïïà Ìï® (ÌÖåÏä§Ìä∏)\n",
    "    persistent_workers=NUM_WORKERS > 0,\n",
    "    prefetch_factor=PREFETCH_FACTOR if NUM_WORKERS > 0 else None,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=None,  # DatasetÏù¥ Ïù¥ÎØ∏ Î∞∞ÏπòÎ•º Î∞òÌôòÌïòÎØÄÎ°ú None\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=NUM_WORKERS > 0,\n",
    "    prefetch_factor=PREFETCH_FACTOR if NUM_WORKERS > 0 else None,\n",
    ")\n",
    "\n",
    "print(\"\\nÏ≤´ Î∞∞Ïπò Î°úÎî© Ï§ë...\")\n",
    "for states, policies, masks, values in train_loader:\n",
    "    print(f\"\\nÎ∞∞Ïπò shape ÌôïÏù∏:\")\n",
    "    print(f\"  States: {states.shape}\")\n",
    "    print(f\"  Policies: {policies.shape}\")\n",
    "    print(f\"  Masks: {masks.shape}\")\n",
    "    print(f\"  Values: {values.shape}\")\n",
    "    break\n",
    "\n",
    "print(\"\\nÎç∞Ïù¥ÌÑ∞ Î°úÎî© Ï§ÄÎπÑ ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÌïôÏäµ ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T19:50:45.267778900Z",
     "start_time": "2026-01-26T19:50:45.187674200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌïôÏäµ ÏÑ§Ï†ï:\n",
      "  Base LR: 0.001 ‚Üí Scaled LR: 0.008000 (8.0x)\n",
      "  Epochs: 10\n",
      "  Batch Size: 4096\n",
      "  Policy Weight: 1.0\n",
      "  Value Weight: 1.0\n",
      "  AMP (Mixed Precision): ÌôúÏÑ±Ìôî\n",
      "\n",
      "TensorBoard Î°úÍ∑∏ ÎîîÎ†âÌÜ†Î¶¨: models/tensorboard\n",
      "TensorBoard Ïã§Ìñâ: tensorboard --logdir=models/tensorboard\n",
      "Î∏åÎùºÏö∞Ï†ÄÏóêÏÑú http://localhost:6006 Ï†ëÏÜç\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ÌïôÏäµ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
    "# =============================================================================\n",
    "BASE_LEARNING_RATE = 0.001  # Í∏∞Ï§Ä Î∞∞Ïπò(100)ÏóêÏÑúÏùò ÌïôÏäµÎ•†\n",
    "\n",
    "# ÏÑ†Ìòï Ïä§ÏºÄÏùºÎßÅ: Î∞∞ÏπòÍ∞Ä NÎ∞∞ Ïª§ÏßÄÎ©¥ ÌïôÏäµÎ•†ÎèÑ NÎ∞∞\n",
    "# (Îã®, ÎÑàÎ¨¥ ÌÅ¨Î©¥ Î∞úÏÇ∞Ìï† Ïàò ÏûàÏñ¥ÏÑú ÏÉÅÌïú ÏÑ§Ï†ï)\n",
    "LR_SCALE = min(BATCH_SIZE / BASE_BATCH_SIZE, 8.0)  # ÏµúÎåÄ 8Î∞∞\n",
    "LEARNING_RATE = BASE_LEARNING_RATE * LR_SCALE\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "POLICY_WEIGHT = 1.0\n",
    "VALUE_WEIGHT = 1.0\n",
    "\n",
    "# =============================================================================\n",
    "# AMP (Automatic Mixed Precision) ÏÑ§Ï†ï\n",
    "# =============================================================================\n",
    "# - GPU Ïó∞ÏÇ∞ÏùÑ float16ÏúºÎ°ú ÏàòÌñâÌï¥ ÏÜçÎèÑ Ìñ•ÏÉÅ + Î©îÎ™®Î¶¨ Ï†àÏïΩ\n",
    "# - GradScalerÎ°ú gradient underflow Î∞©ÏßÄ\n",
    "USE_AMP = torch.cuda.is_available()\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
    "\n",
    "policy_loss_fn = nn.CrossEntropyLoss()\n",
    "value_loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0.0,\n",
    "    amsgrad=False\n",
    ")\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=2\n",
    ")\n",
    "\n",
    "# Î™®Îç∏ Ï†ÄÏû• Í≤ΩÎ°ú\n",
    "MODEL_DIR = Path(\"models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "BEST_MODEL_PATH = MODEL_DIR / \"best_chess_cnn.pth\"\n",
    "LAST_MODEL_PATH = MODEL_DIR / \"last_chess_cnn.pth\"\n",
    "\n",
    "# TensorBoard Writer ÏÉùÏÑ± (ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Í∏∞Î∞ò)\n",
    "writer = create_tensorboard_writer(\"cnn\")\n",
    "\n",
    "print(f\"ÌïôÏäµ ÏÑ§Ï†ï:\")\n",
    "print(f\"  Base LR: {BASE_LEARNING_RATE} ‚Üí Scaled LR: {LEARNING_RATE:.6f} ({LR_SCALE:.1f}x)\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Policy Weight: {POLICY_WEIGHT}\")\n",
    "print(f\"  Value Weight: {VALUE_WEIGHT}\")\n",
    "print(f\"  AMP (Mixed Precision): {'ÌôúÏÑ±Ìôî' if USE_AMP else 'ÎπÑÌôúÏÑ±Ìôî'}\")\n",
    "print(f\"\\nTensorBoard Î°úÍ∑∏ ÎîîÎ†âÌÜ†Î¶¨: {writer.log_dir}\")\n",
    "print(f\"TensorBoard Ïã§Ìñâ: tensorboard --logdir=models/tensorboard\")\n",
    "print(f\"Î∏åÎùºÏö∞Ï†ÄÏóêÏÑú http://localhost:6006 Ï†ëÏÜç\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÌïôÏäµ Ìï®Ïàò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T19:50:46.567827600Z",
     "start_time": "2026-01-26T19:50:46.542239300Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_epoch, validate Ìï®ÏàòÎäî train_utils.pyÏóêÏÑú importÎê®\n",
    "# ÏÇ¨Ïö©Î≤ï:\n",
    "#   train_metrics = train_epoch(model, train_loader, optimizer, ...)\n",
    "#   val_metrics = validate(model, val_loader, ...)\n",
    "print(\"train_epoch, validate Ìï®ÏàòÍ∞Ä train_utils.pyÏóêÏÑú Î°úÎìúÎêòÏóàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÌïôÏäµ Ïã§Ìñâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-26T19:50:47.584804800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ÌïôÏäµ ÏãúÏûë\n",
      "============================================================\n",
      "\n",
      "Epoch 1/10\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÌïôÏäµ Ï§ë: 5265it [13:19,  6.58it/s, loss=3.6266, policy=1.7858, value=1.8408]                          \n",
      "Í≤ÄÏ¶ù Ï§ë: 572it [02:32,  3.75it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÌïôÏäµ Í≤∞Í≥º:\n",
      "  Policy Loss: 2.0297\n",
      "  Value Loss: 1.9252\n",
      "  Total Loss: 3.9548\n",
      "\n",
      "Í≤ÄÏ¶ù Í≤∞Í≥º:\n",
      "  Policy Loss: 1.8789\n",
      "  Value Loss: 1.9254\n",
      "  Total Loss: 3.8043\n",
      "  Accuracy: 0.4208 (42.08%)\n",
      "  ÌòÑÏû¨ ÌïôÏäµÎ•†: 0.008000\n",
      "\n",
      "‚úÖ ÏµúÍ≥† Î™®Îç∏ Ï†ÄÏû•! (Loss: 3.8043)\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÌïôÏäµ Ï§ë: 5265it [13:08,  6.68it/s, loss=2.7835, policy=1.7835, value=1.0000]                          \n",
      "Í≤ÄÏ¶ù Ï§ë: 572it [02:33,  3.72it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÌïôÏäµ Í≤∞Í≥º:\n",
      "  Policy Loss: 1.8107\n",
      "  Value Loss: 1.4835\n",
      "  Total Loss: 3.2942\n",
      "\n",
      "Í≤ÄÏ¶ù Í≤∞Í≥º:\n",
      "  Policy Loss: 1.8083\n",
      "  Value Loss: 0.9136\n",
      "  Total Loss: 2.7220\n",
      "  Accuracy: 0.4375 (43.75%)\n",
      "  ÌòÑÏû¨ ÌïôÏäµÎ•†: 0.008000\n",
      "\n",
      "‚úÖ ÏµúÍ≥† Î™®Îç∏ Ï†ÄÏû•! (Loss: 2.7220)\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÌïôÏäµ Ï§ë: 5265it [13:17,  6.60it/s, loss=2.6653, policy=1.6654, value=1.0000]                          \n",
      "Í≤ÄÏ¶ù Ï§ë: 572it [02:37,  3.62it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÌïôÏäµ Í≤∞Í≥º:\n",
      "  Policy Loss: 1.7483\n",
      "  Value Loss: 0.9138\n",
      "  Total Loss: 2.6620\n",
      "\n",
      "Í≤ÄÏ¶ù Í≤∞Í≥º:\n",
      "  Policy Loss: 1.7892\n",
      "  Value Loss: 0.9136\n",
      "  Total Loss: 2.7029\n",
      "  Accuracy: 0.4426 (44.26%)\n",
      "  ÌòÑÏû¨ ÌïôÏäµÎ•†: 0.008000\n",
      "\n",
      "‚úÖ ÏµúÍ≥† Î™®Îç∏ Ï†ÄÏû•! (Loss: 2.7029)\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÌïôÏäµ Ï§ë: 5265it [13:18,  6.60it/s, loss=2.4844, policy=1.5257, value=0.9587]                          \n",
      "Í≤ÄÏ¶ù Ï§ë: 572it [02:37,  3.63it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÌïôÏäµ Í≤∞Í≥º:\n",
      "  Policy Loss: 1.7124\n",
      "  Value Loss: 0.9138\n",
      "  Total Loss: 2.6262\n",
      "\n",
      "Í≤ÄÏ¶ù Í≤∞Í≥º:\n",
      "  Policy Loss: 1.7814\n",
      "  Value Loss: 0.9136\n",
      "  Total Loss: 2.6950\n",
      "  Accuracy: 0.4458 (44.58%)\n",
      "  ÌòÑÏû¨ ÌïôÏäµÎ•†: 0.008000\n",
      "\n",
      "‚úÖ ÏµúÍ≥† Î™®Îç∏ Ï†ÄÏû•! (Loss: 2.6950)\n",
      "\n",
      "Epoch 5/10\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÌïôÏäµ Ï§ë: 5265it [13:41,  6.41it/s, loss=2.5796, policy=1.5796, value=1.0000]                          \n",
      "Í≤ÄÏ¶ù Ï§ë: 572it [02:34,  3.70it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÌïôÏäµ Í≤∞Í≥º:\n",
      "  Policy Loss: 1.6874\n",
      "  Value Loss: 0.9138\n",
      "  Total Loss: 2.6012\n",
      "\n",
      "Í≤ÄÏ¶ù Í≤∞Í≥º:\n",
      "  Policy Loss: 1.7733\n",
      "  Value Loss: 0.9136\n",
      "  Total Loss: 2.6870\n",
      "  Accuracy: 0.4469 (44.69%)\n",
      "  ÌòÑÏû¨ ÌïôÏäµÎ•†: 0.008000\n",
      "\n",
      "‚úÖ ÏµúÍ≥† Î™®Îç∏ Ï†ÄÏû•! (Loss: 2.6870)\n",
      "\n",
      "Epoch 6/10\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÌïôÏäµ Ï§ë: 5265it [13:04,  6.71it/s, loss=2.3611, policy=1.4779, value=0.8832]                          \n",
      "Í≤ÄÏ¶ù Ï§ë: 572it [02:33,  3.72it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÌïôÏäµ Í≤∞Í≥º:\n",
      "  Policy Loss: 1.6694\n",
      "  Value Loss: 0.9138\n",
      "  Total Loss: 2.5832\n",
      "\n",
      "Í≤ÄÏ¶ù Í≤∞Í≥º:\n",
      "  Policy Loss: 1.7862\n",
      "  Value Loss: 0.9136\n",
      "  Total Loss: 2.6999\n",
      "  Accuracy: 0.4495 (44.95%)\n",
      "  ÌòÑÏû¨ ÌïôÏäµÎ•†: 0.008000\n",
      "\n",
      "Epoch 7/10\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÌïôÏäµ Ï§ë: 5265it [13:06,  6.69it/s, loss=2.5961, policy=1.5962, value=1.0000]                          \n",
      "Í≤ÄÏ¶ù Ï§ë: 572it [02:40,  3.57it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÌïôÏäµ Í≤∞Í≥º:\n",
      "  Policy Loss: 1.6559\n",
      "  Value Loss: 0.9138\n",
      "  Total Loss: 2.5697\n",
      "\n",
      "Í≤ÄÏ¶ù Í≤∞Í≥º:\n",
      "  Policy Loss: 1.7889\n",
      "  Value Loss: 0.9136\n",
      "  Total Loss: 2.7026\n",
      "  Accuracy: 0.4480 (44.80%)\n",
      "  ÌòÑÏû¨ ÌïôÏäµÎ•†: 0.008000\n",
      "\n",
      "Epoch 8/10\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÌïôÏäµ Ï§ë:   6%|‚ñå         | 278/4943 [00:46<13:03,  5.95it/s, loss=2.6431, policy=1.6739, value=0.9692]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m train_dataset.set_epoch(epoch)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# ÌïôÏäµ\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m train_metrics = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_loss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_loss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mPOLICY_WEIGHT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVALUE_WEIGHT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUSE_AMP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRAIN_STEPS_PER_EPOCH\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Í≤ÄÏ¶ù Ï†Ñ Î©îÎ™®Î¶¨ Ï†ïÎ¶¨ (ÌïôÏäµ ÏõåÏª§ Ï¢ÖÎ£å)\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# train_loaderÏùò ÏõåÏª§Îì§ÏùÑ Ï¢ÖÎ£åÌïòÏó¨ Î©îÎ™®Î¶¨ ÌôïÎ≥¥\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# iteratorÎ•º NoneÏúºÎ°ú ÏÑ§Ï†ïÌïòÎ©¥ ÏõåÏª§Í∞Ä ÏûêÎèôÏúºÎ°ú Ï¢ÖÎ£åÎê®\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, optimizer, policy_loss_fn, value_loss_fn, policy_weight, value_weight, device, scaler, use_amp, total_steps)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# AMP: scalerÎ°ú backward (gradient scaling)\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     scaler.unscale_(optimizer)\n\u001b[32m     42\u001b[39m     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m, norm_type=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py:629\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    619\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    621\u001b[39m         Tensor.backward,\n\u001b[32m    622\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    627\u001b[39m         inputs=inputs,\n\u001b[32m    628\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py:357\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    354\u001b[39m     tensors = \u001b[38;5;28mtuple\u001b[39m(tensors)\n\u001b[32m    356\u001b[39m grad_tensors_ = _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m grad_tensors_ = \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    359\u001b[39m     retain_graph = create_graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py:230\u001b[39m, in \u001b[36m_make_grads\u001b[39m\u001b[34m(outputs, grads, is_grads_batched)\u001b[39m\n\u001b[32m    227\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, torch.Tensor):\n\u001b[32m    228\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mExpected output to be a torch.Tensor\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    229\u001b[39m         new_grads.append(\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m             \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m         )\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    233\u001b[39m     new_grads.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ÌïôÏäµ ÌûàÏä§ÌÜ†Î¶¨\n",
    "train_history = {\n",
    "    'policy_loss': [],\n",
    "    'value_loss': [],\n",
    "    'total_loss': []\n",
    "}\n",
    "\n",
    "val_history = {\n",
    "    'policy_loss': [],\n",
    "    'value_loss': [],\n",
    "    'total_loss': [],\n",
    "    'accuracy': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ÌïôÏäµ ÏãúÏûë\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # ÏóêÌè≠ ÏÑ§Ï†ï (ÌååÏùº ÏàúÏÑú ÏÖîÌîåÏóê ÏÇ¨Ïö©)\n",
    "    train_dataset.set_epoch(epoch)\n",
    "    \n",
    "    # ÌïôÏäµ\n",
    "    train_metrics = train_epoch(\n",
    "        model, train_loader, optimizer, policy_loss_fn, value_loss_fn,\n",
    "        POLICY_WEIGHT, VALUE_WEIGHT, device,\n",
    "        scaler=scaler, use_amp=USE_AMP, total_steps=TRAIN_STEPS_PER_EPOCH\n",
    "    )\n",
    "    \n",
    "    # Í≤ÄÏ¶ù Ï†Ñ Î©îÎ™®Î¶¨ Ï†ïÎ¶¨ (ÌïôÏäµ ÏõåÏª§ Ï¢ÖÎ£å)\n",
    "    # train_loaderÏùò ÏõåÏª§Îì§ÏùÑ Ï¢ÖÎ£åÌïòÏó¨ Î©îÎ™®Î¶¨ ÌôïÎ≥¥\n",
    "    # iteratorÎ•º NoneÏúºÎ°ú ÏÑ§Ï†ïÌïòÎ©¥ ÏõåÏª§Í∞Ä ÏûêÎèôÏúºÎ°ú Ï¢ÖÎ£åÎê®\n",
    "    try:\n",
    "        if hasattr(train_loader, '_iterator') and train_loader._iterator is not None:\n",
    "            train_loader._iterator._shutdown_workers()\n",
    "            train_loader._iterator = None\n",
    "    except:\n",
    "        pass  # iteratorÍ∞Ä ÏóÜÍ±∞ÎÇò Ïù¥ÎØ∏ Ï¢ÖÎ£åÎêú Í≤ΩÏö∞ Î¨¥Ïãú\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Í≤ÄÏ¶ù\n",
    "    val_metrics = validate(\n",
    "        model, val_loader, policy_loss_fn, value_loss_fn,\n",
    "        POLICY_WEIGHT, VALUE_WEIGHT, device,\n",
    "        use_amp=USE_AMP, total_steps=VAL_STEPS_PER_EPOCH\n",
    "    )\n",
    "    \n",
    "    # ÌûàÏä§ÌÜ†Î¶¨ Ï†ÄÏû•\n",
    "    train_history['policy_loss'].append(train_metrics['policy_loss'])\n",
    "    train_history['value_loss'].append(train_metrics['value_loss'])\n",
    "    train_history['total_loss'].append(train_metrics['total_loss'])\n",
    "    \n",
    "    val_history['policy_loss'].append(val_metrics['policy_loss'])\n",
    "    val_history['value_loss'].append(val_metrics['value_loss'])\n",
    "    val_history['total_loss'].append(val_metrics['total_loss'])\n",
    "    val_history['accuracy'].append(val_metrics['accuracy'])\n",
    "    \n",
    "    # =============================================================================\n",
    "    # TensorBoard Î°úÍπÖ\n",
    "    # =============================================================================\n",
    "    # ÏÜêÏã§ Í∏∞Î°ù\n",
    "    writer.add_scalars('Loss/Total', {\n",
    "        'train': train_metrics['total_loss'],\n",
    "        'val': val_metrics['total_loss']\n",
    "    }, epoch)\n",
    "    writer.add_scalars('Loss/Policy', {\n",
    "        'train': train_metrics['policy_loss'],\n",
    "        'val': val_metrics['policy_loss']\n",
    "    }, epoch)\n",
    "    writer.add_scalars('Loss/Value', {\n",
    "        'train': train_metrics['value_loss'],\n",
    "        'val': val_metrics['value_loss']\n",
    "    }, epoch)\n",
    "    \n",
    "    # Ï†ïÌôïÎèÑ Í∏∞Î°ù\n",
    "    writer.add_scalar('Accuracy/Top1', val_metrics['accuracy'], epoch)\n",
    "    writer.add_scalar('Accuracy/Top3', val_metrics['top3_acc'], epoch)\n",
    "    writer.add_scalar('Accuracy/Top5', val_metrics['top5_acc'], epoch)\n",
    "    writer.add_scalar('Accuracy/Top10', val_metrics['top10_acc'], epoch)\n",
    "    writer.add_scalar('Accuracy/Masked_Top1', val_metrics['masked_acc'], epoch)\n",
    "    \n",
    "    # Rank Î∂ÑÏÑù Í∏∞Î°ù\n",
    "    writer.add_scalar('Rank/MRR', val_metrics['mrr'], epoch)\n",
    "    writer.add_scalar('Rank/Avg_Rank', val_metrics['avg_rank'], epoch)\n",
    "    \n",
    "    # Î∂ÑÌè¨ Î∂ÑÏÑù Í∏∞Î°ù\n",
    "    writer.add_scalar('Distribution/Entropy', val_metrics['entropy'], epoch)\n",
    "    writer.add_scalar('Distribution/Legal_Prob_Mass', val_metrics['legal_prob_mass'], epoch)\n",
    "    \n",
    "    # ÌïôÏäµÎ•† Í∏∞Î°ù\n",
    "    writer.add_scalar('LearningRate', optimizer.param_groups[0]['lr'], epoch)\n",
    "    \n",
    "    # Í≤∞Í≥º Ï∂úÎ†•\n",
    "    print(f\"\\nÌïôÏäµ Í≤∞Í≥º:\")\n",
    "    print(f\"  Policy Loss: {train_metrics['policy_loss']:.4f}\")\n",
    "    print(f\"  Value Loss: {train_metrics['value_loss']:.4f}\")\n",
    "    print(f\"  Total Loss: {train_metrics['total_loss']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nÍ≤ÄÏ¶ù Í≤∞Í≥º:\")\n",
    "    print(f\"  Policy Loss: {val_metrics['policy_loss']:.4f}\")\n",
    "    print(f\"  Value Loss: {val_metrics['value_loss']:.4f}\")\n",
    "    print(f\"  Total Loss: {val_metrics['total_loss']:.4f}\")\n",
    "    print(f\"  --- Ï†ïÌôïÎèÑ ---\")\n",
    "    print(f\"  Top-1 Acc: {val_metrics['accuracy']*100:.2f}% | Top-3: {val_metrics['top3_acc']*100:.2f}% | Top-5: {val_metrics['top5_acc']*100:.2f}% | Top-10: {val_metrics['top10_acc']*100:.2f}%\")\n",
    "    print(f\"  Masked Top-1 Acc: {val_metrics['masked_acc']*100:.2f}%\")\n",
    "    print(f\"  --- Rank Î∂ÑÏÑù ---\")\n",
    "    print(f\"  MRR: {val_metrics['mrr']:.4f} | Avg Rank: {val_metrics['avg_rank']:.2f}\")\n",
    "    print(f\"  --- Î∂ÑÌè¨ Î∂ÑÏÑù ---\")\n",
    "    print(f\"  Entropy (legal): {val_metrics['entropy']:.4f} | Legal Prob Mass: {val_metrics['legal_prob_mass']*100:.2f}%\")\n",
    "    \n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_metrics['total_loss'])\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if old_lr != new_lr:\n",
    "        print(f\"\\nüìâ ÌïôÏäµÎ•† Í∞êÏÜå: {old_lr:.6f} -> {new_lr:.6f}\")\n",
    "    else:\n",
    "        print(f\"  ÌòÑÏû¨ ÌïôÏäµÎ•†: {new_lr:.6f}\")\n",
    "    \n",
    "    if val_metrics['total_loss'] < best_val_loss:\n",
    "        best_val_loss = val_metrics['total_loss']\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_loss': val_metrics['total_loss'],\n",
    "            'val_accuracy': val_metrics['accuracy'],\n",
    "            'train_loss': train_metrics['total_loss'],\n",
    "            'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "            'model_config': {'num_channels': 256},\n",
    "        }\n",
    "        torch.save(checkpoint, BEST_MODEL_PATH)\n",
    "        print(f\"\\n‚úÖ ÏµúÍ≥† Î™®Îç∏ Ï†ÄÏû•! (Loss: {best_val_loss:.4f})\")\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'val_loss': val_metrics['total_loss'],\n",
    "        'val_accuracy': val_metrics['accuracy'],\n",
    "        'train_loss': train_metrics['total_loss'],\n",
    "        'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "        'model_config': {'num_channels': 256},\n",
    "    }\n",
    "    torch.save(checkpoint, LAST_MODEL_PATH)\n",
    "\n",
    "# TensorBoard writer Îã´Í∏∞\n",
    "writer.close()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ÌïôÏäµ ÏôÑÎ£å!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ÏµúÍ≥† Í≤ÄÏ¶ù Loss: {best_val_loss:.4f}\")\n",
    "print(f\"ÏµúÍ≥† Î™®Îç∏: {BEST_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÌïôÏäµ Í≥°ÏÑ† ÏãúÍ∞ÅÌôî"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m15\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Total Loss\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m axes[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m].plot(\u001b[43mtrain_history\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtotal_loss\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mTrain\u001b[39m\u001b[33m'\u001b[39m, marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m axes[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m].plot(val_history[\u001b[33m'\u001b[39m\u001b[33mtotal_loss\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mValidation\u001b[39m\u001b[33m'\u001b[39m, marker=\u001b[33m'\u001b[39m\u001b[33ms\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m axes[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m].set_title(\u001b[33m'\u001b[39m\u001b[33mTotal Loss\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loss Í≥°ÏÑ†\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Total Loss\n",
    "axes[0, 0].plot(train_history['total_loss'], label='Train', marker='o')\n",
    "axes[0, 0].plot(val_history['total_loss'], label='Validation', marker='s')\n",
    "axes[0, 0].set_title('Total Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Policy Loss\n",
    "axes[0, 1].plot(train_history['policy_loss'], label='Train', marker='o')\n",
    "axes[0, 1].plot(val_history['policy_loss'], label='Validation', marker='s')\n",
    "axes[0, 1].set_title('Policy Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Value Loss\n",
    "axes[1, 0].plot(train_history['value_loss'], label='Train', marker='o')\n",
    "axes[1, 0].plot(val_history['value_loss'], label='Validation', marker='s')\n",
    "axes[1, 0].set_title('Value Loss')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[1, 1].plot(val_history['accuracy'], label='Validation', marker='s', color='green')\n",
    "axes[1, 1].set_title('Policy Accuracy')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_DIR / 'training_curves.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"ÌïôÏäµ Í≥°ÏÑ† Ï†ÄÏû• ÏôÑÎ£å:\", MODEL_DIR / 'training_curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Î™®Îç∏ ÌèâÍ∞Ä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Í≤ÄÏ¶ù Ï†ÑÏö© ÏÑ§Ï†ï (ÌïôÏäµ ÏóÜÏù¥ Ïã§Ìñâ Ïãú)\n",
    "\n",
    "ÌïôÏäµ ÏóÜÏù¥ Ï†ÄÏû•Îêú Î™®Îç∏Îßå ÌèâÍ∞ÄÌï† Îïå ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
    "- **Cell 1 (ÏûÑÌè¨Ìä∏) ‚Üí Cell 3 (Î™®Îç∏ ÏÉùÏÑ±) ‚Üí Ïù¥ ÏÖÄ ‚Üí Î™®Îç∏ ÌèâÍ∞Ä ÏÖÄ** ÏàúÏÑúÎ°ú Ïã§Ìñâ\n",
    "- train_loaderÎ•º ÏÉùÏÑ±ÌïòÏßÄ ÏïäÏïÑ Î©îÎ™®Î¶¨ Ï†àÏïΩ\n",
    "- num_workers=0ÏúºÎ°ú OOM Î∞©ÏßÄ\n",
    "- validate Ìï®ÏàòÎäî Cell 1ÏóêÏÑú train_utils.pyÎ°úÎ∂ÄÌÑ∞ ÏûêÎèô importÎê®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_parquet_file_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m CHUNK_SIZE = \u001b[32m32768\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ÌååÏùº Ï†ïÎ≥¥ ÏàòÏßë Î∞è Î∂ÑÌï† (val_filesÎßå ÏÇ¨Ïö©)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m parquet_files, file_lengths = \u001b[43mget_parquet_file_info\u001b[49m(PARQUET_DIR, \u001b[33m\"\u001b[39m\u001b[33mchess_samples_*.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m _, val_files, _, val_lengths, _, val_samples = split_files_by_ratio(\n\u001b[32m     13\u001b[39m     parquet_files, \n\u001b[32m     14\u001b[39m     file_lengths, \n\u001b[32m     15\u001b[39m     train_ratio=TRAIN_RATIO,\n\u001b[32m     16\u001b[39m     shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ÏÖãÎßå ÏÉùÏÑ±\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'get_parquet_file_info' is not defined"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Í≤ÄÏ¶ù Ï†ÑÏö© ÏÑ§Ï†ï (ÌïôÏäµ ÏóÜÏù¥ Î™®Îç∏ ÌèâÍ∞ÄÎßå Ìï† Îïå ÏÇ¨Ïö©)\n",
    "# =============================================================================\n",
    "# Îç∞Ïù¥ÌÑ∞ ÎîîÎ†âÌÜ†Î¶¨ ÏÑ§Ï†ï\n",
    "PARQUET_DIR = \"data/parquet\"\n",
    "TRAIN_RATIO = 0.9\n",
    "BATCH_SIZE = 4096\n",
    "CHUNK_SIZE = 32768\n",
    "\n",
    "# ÌååÏùº Ï†ïÎ≥¥ ÏàòÏßë Î∞è Î∂ÑÌï† (val_filesÎßå ÏÇ¨Ïö©)\n",
    "parquet_files, file_lengths = get_parquet_file_info(PARQUET_DIR, \"chess_samples_*.parquet\")\n",
    "_, val_files, _, val_lengths, _, val_samples = split_files_by_ratio(\n",
    "    parquet_files, \n",
    "    file_lengths, \n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ÏÖãÎßå ÏÉùÏÑ±\n",
    "print(\"\\nÍ≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ± Ï§ë...\")\n",
    "val_dataset = ParquetChessDataset(\n",
    "    parquet_files=val_files,\n",
    "    file_lengths=val_lengths,\n",
    "    shuffle_files=False,\n",
    "    seed=42,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    chunk_size=CHUNK_SIZE\n",
    ")\n",
    "\n",
    "print(f\"Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞: {val_dataset.estimated_length:,} ÏÉòÌîå\")\n",
    "\n",
    "VAL_STEPS_PER_EPOCH = val_dataset.estimated_length // BATCH_SIZE\n",
    "print(f\"Í≤ÄÏ¶ù Ïù¥ÌÑ∞Î†àÏù¥ÏÖò: {VAL_STEPS_PER_EPOCH:,} steps\")\n",
    "\n",
    "# Í≤ÄÏ¶ùÏö© DataLoader (ÏõåÏª§ ÏóÜÏù¥ - Î©îÎ™®Î¶¨ Ï†àÏïΩ)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=None,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # ÏõåÏª§ ÏóÜÏù¥ Ïã§Ìñâ (OOM Î∞©ÏßÄ)\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "# Loss Ìï®Ïàò Ï†ïÏùò\n",
    "policy_loss_fn = nn.CrossEntropyLoss()\n",
    "value_loss_fn = nn.MSELoss()\n",
    "\n",
    "# Î™®Îç∏ Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "MODEL_DIR = Path(\"models\")\n",
    "BEST_MODEL_PATH = MODEL_DIR / \"best_chess_cnn.pth\"\n",
    "LAST_MODEL_PATH = MODEL_DIR / \"last_chess_cnn.pth\"\n",
    "\n",
    "POLICY_WEIGHT = 1.0\n",
    "VALUE_WEIGHT = 1.0\n",
    "USE_AMP = torch.cuda.is_available()\n",
    "\n",
    "print(\"\\nÍ≤ÄÏ¶ù Ï§ÄÎπÑ ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î°úÎìúÎêú Î™®Îç∏ Ï†ïÎ≥¥:\n",
      "  Epoch: 5\n",
      "  Validation Loss: 2.6870\n",
      "  Validation Accuracy: 0.4469 (44.69%)\n",
      "  Learning Rate: 0.008000\n",
      "  Train Loss: 2.6012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Í≤ÄÏ¶ù Ï§ë:   0%|          | 0/537 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_10001/969328209.py\", line 15, in <module>\n",
      "    final_metrics = validate(\n",
      "                    ^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_10001/2532236701.py\", line 107, in validate\n",
      "    for states, policies, masks, values in tqdm(dataloader, desc=\"Í≤ÄÏ¶ù Ï§ë\", total=total_steps):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 740, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1505, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1464, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1295, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 10214) is killed by signal: Killed. \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2201, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1064, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 872, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 757, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, context, tb_offset) if etb else []\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 859, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/stack_data/core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/stack_data/utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/stack_data/core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/stack_data/core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/executing/executing.py\", line 224, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/executing/executing.py\", line 143, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/executing/executing.py\", line 172, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/executing/executing.py\", line 183, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/executing/executing.py\", line 123, in __init__\n",
      "    self.tree = ast.parse(self.text, filename=filename)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 10357) is killed by signal: Killed. \n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(BEST_MODEL_PATH, map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Î°úÎìúÎêú Î™®Îç∏ Ï†ïÎ≥¥:\")\n",
    "print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"  Validation Loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"  Validation Accuracy: {checkpoint['val_accuracy']:.4f} ({checkpoint['val_accuracy']*100:.2f}%)\")\n",
    "if 'learning_rate' in checkpoint:\n",
    "    print(f\"  Learning Rate: {checkpoint['learning_rate']:.6f}\")\n",
    "if 'train_loss' in checkpoint:\n",
    "    print(f\"  Train Loss: {checkpoint['train_loss']:.4f}\")\n",
    "\n",
    "# ÏµúÏ¢Ö Í≤ÄÏ¶ù\n",
    "final_metrics = validate(\n",
    "    model, val_loader, policy_loss_fn, value_loss_fn,\n",
    "    POLICY_WEIGHT, VALUE_WEIGHT, device,\n",
    "    use_amp=USE_AMP, total_steps=VAL_STEPS_PER_EPOCH\n",
    ")\n",
    "\n",
    "print(f\"\\nÏµúÏ¢Ö Í≤ÄÏ¶ù Í≤∞Í≥º:\")\n",
    "print(f\"  Policy Loss: {final_metrics['policy_loss']:.4f}\")\n",
    "print(f\"  Value Loss: {final_metrics['value_loss']:.4f}\")\n",
    "print(f\"  Total Loss: {final_metrics['total_loss']:.4f}\")\n",
    "print(f\"  --- Ï†ïÌôïÎèÑ ---\")\n",
    "print(f\"  Top-1 Acc: {final_metrics['accuracy']*100:.2f}% | Top-3: {final_metrics['top3_acc']*100:.2f}% | Top-5: {final_metrics['top5_acc']*100:.2f}% | Top-10: {final_metrics['top10_acc']*100:.2f}%\")\n",
    "print(f\"  Masked Top-1 Acc: {final_metrics['masked_acc']*100:.2f}%\")\n",
    "print(f\"  --- Rank Î∂ÑÏÑù ---\")\n",
    "print(f\"  MRR: {final_metrics['mrr']:.4f} | Avg Rank: {final_metrics['avg_rank']:.2f}\")\n",
    "print(f\"  --- Î∂ÑÌè¨ Î∂ÑÏÑù ---\")\n",
    "print(f\"  Entropy (legal): {final_metrics['entropy']:.4f} | Legal Prob Mass: {final_metrics['legal_prob_mass']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÏÉòÌîå ÏòàÏ∏° ÌôïÏù∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 3587) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmpty\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:1295\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/queues.py:114\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[31mEmpty\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m non_blocking = torch.cuda.is_available()\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:496\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    494\u001b[39m         \u001b[38;5;28mself\u001b[39m._iterator = \u001b[38;5;28mself\u001b[39m._get_iterator()\n\u001b[32m    495\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:1271\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._reset\u001b[39m\u001b[34m(self, loader, first_iter)\u001b[39m\n\u001b[32m   1269\u001b[39m resume_iteration_cnt = \u001b[38;5;28mself\u001b[39m._num_workers\n\u001b[32m   1270\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m resume_iteration_cnt > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1271\u001b[39m     return_idx, return_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1272\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_idx, _utils.worker._ResumeIteration):\n\u001b[32m   1273\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m return_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:1464\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1460\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1461\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1462\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1463\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1464\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1465\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1466\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:1308\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1307\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1308\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1309\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1310\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 3587) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Î™á Í∞ú ÏÉòÌîåÎ°ú ÏòàÏ∏° ÌôïÏù∏\n",
    "model.eval()\n",
    "non_blocking = torch.cuda.is_available()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for states, policies, masks, values in val_loader:\n",
    "        states = states.to(device, non_blocking=non_blocking)\n",
    "        masks = masks.to(device, non_blocking=non_blocking)\n",
    "        \n",
    "        policy_logits, value_pred = model(states, masks)\n",
    "        policy_probs = torch.softmax(policy_logits, dim=1)\n",
    "        pred_policies = policy_logits.argmax(dim=1)\n",
    "        \n",
    "        print(\"ÏÉòÌîå ÏòàÏ∏°:\")\n",
    "        for i in range(min(5, len(states))):\n",
    "            print(f\"\\nÏÉòÌîå {i+1}:\")\n",
    "            print(f\"  Ïã§Ï†ú Policy: {policies[i].item()}\")\n",
    "            print(f\"  ÏòàÏ∏° Policy: {pred_policies[i].item()}\")\n",
    "            print(f\"  Ï†ïÌôïÎèÑ: {'‚úÖ' if pred_policies[i] == policies[i] else '‚ùå'}\")\n",
    "            print(f\"  Ïã§Ï†ú Value: {values[i].item():.4f}\")\n",
    "            print(f\"  ÏòàÏ∏° Value: {value_pred[i].item():.4f}\")\n",
    "            print(f\"  ÏòàÏ∏° ÌôïÎ•† (top-1): {policy_probs[i].max().item():.4f}\")\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Î™®Îç∏ Ï†ÄÏû• (Í∞ïÌôîÌïôÏäµÏö©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í∞ïÌôîÌïôÏäµÏö© Î™®Îç∏ Ï†ÄÏû• (state_dictÎßå)\n",
    "RL_MODEL_PATH = MODEL_DIR / \"chess_cnn_rl.pth\"\n",
    "torch.save(model.state_dict(), RL_MODEL_PATH)\n",
    "\n",
    "print(f\"Í∞ïÌôîÌïôÏäµÏö© Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {RL_MODEL_PATH}\")\n",
    "print(f\"\\nÍ∞ïÌôîÌïôÏäµÏóêÏÑú ÏÇ¨Ïö© Î∞©Î≤ï:\")\n",
    "print(f\"  model = ChessCNN(num_channels=256)\")\n",
    "print(f\"  model.load_state_dict(torch.load('{RL_MODEL_PATH}'))\")\n",
    "print(f\"  model.eval()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
